{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dbbaec9-c614-4f59-bb6e-836e670d79a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "XGBOOST MULTI-CLASS CLASSIFICATION (NOISE-ROBUST)\n",
      "================================================================================\n",
      "\n",
      "[1/8] Loading data...\n",
      "Training data shape: (27617, 411)\n",
      "Test data shape: (13082, 411)\n",
      "\n",
      "[2/8] Preprocessing data...\n",
      "After cleaning: 27617 samples, 411 features\n",
      "Features with missing values: 1/411\n",
      "  Max missing %: 0.50%\n",
      "  Mean missing %: 0.50%\n",
      "\n",
      "Class distribution:\n",
      "  Class 1: 8874 samples (32.13%)\n",
      "  Class 2: 6127 samples (22.19%)\n",
      "  Class 3: 8483 samples (30.72%)\n",
      "  Class 4: 4133 samples (14.97%)\n",
      "⚠️  Dataset appears imbalanced - will compute class weights\n",
      "Class weights: [0.77803133 1.12685654 0.81389249 1.67051778]\n",
      "\n",
      "[3/8] Applying median imputation...\n",
      "Feature count: 411\n",
      "\n",
      "[4/8] Configuring XGBoost parameters (noise-robust)...\n",
      "\n",
      "[5/8] Training with 5-fold cross-validation...\n",
      "\n",
      "--- Configuration 1/4 ---\n",
      "LR: 0.03, Depth: 7, Min_child: 30, Gamma: 0.1\n",
      "  Fold 1: Accuracy = 0.9155, Best iteration = 1499\n",
      "  Fold 2: Accuracy = 0.9003, Best iteration = 1499\n",
      "  Fold 3: Accuracy = 0.9136, Best iteration = 1499\n",
      "  Fold 4: Accuracy = 0.9098, Best iteration = 1499\n",
      "  Fold 5: Accuracy = 0.9035, Best iteration = 1499\n",
      "  → CV Score: 0.9085 ± 0.0058\n",
      "  → Avg best iteration: 1499\n",
      "\n",
      "--- Configuration 2/4 ---\n",
      "LR: 0.02, Depth: 6, Min_child: 40, Gamma: 0.15\n",
      "  Fold 1: Accuracy = 0.9080, Best iteration = 1499\n",
      "  Fold 2: Accuracy = 0.8916, Best iteration = 1499\n",
      "  Fold 3: Accuracy = 0.9075, Best iteration = 1499\n",
      "  Fold 4: Accuracy = 0.8999, Best iteration = 1499\n",
      "  Fold 5: Accuracy = 0.8921, Best iteration = 1499\n",
      "  → CV Score: 0.8998 ± 0.0071\n",
      "  → Avg best iteration: 1499\n",
      "\n",
      "--- Configuration 3/4 ---\n",
      "LR: 0.04, Depth: 8, Min_child: 25, Gamma: 0.05\n",
      "  Fold 1: Accuracy = 0.9189, Best iteration = 1499\n",
      "  Fold 2: Accuracy = 0.9031, Best iteration = 1494\n",
      "  Fold 3: Accuracy = 0.9153, Best iteration = 1497\n",
      "  Fold 4: Accuracy = 0.9131, Best iteration = 1499\n",
      "  Fold 5: Accuracy = 0.9049, Best iteration = 1481\n",
      "  → CV Score: 0.9111 ± 0.0061\n",
      "  → Avg best iteration: 1494\n",
      "\n",
      "--- Configuration 4/4 ---\n",
      "LR: 0.025, Depth: 7, Min_child: 35, Gamma: 0.12\n",
      "  Fold 1: Accuracy = 0.9142, Best iteration = 1499\n",
      "  Fold 2: Accuracy = 0.8968, Best iteration = 1499\n",
      "  Fold 3: Accuracy = 0.9087, Best iteration = 1499\n",
      "  Fold 4: Accuracy = 0.9089, Best iteration = 1499\n",
      "  Fold 5: Accuracy = 0.8986, Best iteration = 1499\n",
      "  → CV Score: 0.9055 ± 0.0066\n",
      "  → Avg best iteration: 1499\n",
      "\n",
      "✓ Best configuration: Config 3\n",
      "  CV Score: 0.9111 ± 0.0061\n",
      "\n",
      "[6/8] Detailed validation metrics...\n",
      "\n",
      "Overall Validation Accuracy: 0.9111\n",
      "\n",
      "Class-wise AUC scores:\n",
      "  Class 1 AUC: 0.9914\n",
      "  Class 2 AUC: 0.9896\n",
      "  Class 3 AUC: 0.9905\n",
      "  Class 4 AUC: 0.9772\n",
      "  Macro-average AUC: 0.9871\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 1     0.9114    0.9647    0.9373      8874\n",
      "     Class 2     0.8771    0.9305    0.9030      6127\n",
      "     Class 3     0.9477    0.9243    0.9358      8483\n",
      "     Class 4     0.8864    0.7399    0.8065      4133\n",
      "\n",
      "    accuracy                         0.9111     27617\n",
      "   macro avg     0.9056    0.8899    0.8957     27617\n",
      "weighted avg     0.9112    0.9111    0.9097     27617\n",
      "\n",
      "\n",
      "[7/8] Analyzing feature importance...\n",
      "\n",
      "Top 20 most important features:\n",
      "  Feature 85: 18.24\n",
      "  Feature 346: 12.59\n",
      "  Feature 84: 11.05\n",
      "  Feature 355: 10.59\n",
      "  Feature 357: 10.36\n",
      "  Feature 354: 10.26\n",
      "  Feature 347: 10.20\n",
      "  Feature 124: 9.96\n",
      "  Feature 336: 9.87\n",
      "  Feature 86: 9.62\n",
      "  Feature 356: 9.43\n",
      "  Feature 88: 8.93\n",
      "  Feature 337: 8.83\n",
      "  Feature 66: 8.55\n",
      "  Feature 348: 8.48\n",
      "  Feature 236: 8.00\n",
      "  Feature 96: 7.71\n",
      "  Feature 185: 7.70\n",
      "  Feature 143: 7.67\n",
      "  Feature 165: 7.50\n",
      "\n",
      "[8/8] Generating ensemble predictions on test set...\n",
      "  Training ensemble model 1/8 (seed=42)...\n",
      "  Training ensemble model 2/8 (seed=123)...\n",
      "  Training ensemble model 3/8 (seed=456)...\n",
      "  Training ensemble model 4/8 (seed=789)...\n",
      "  Training ensemble model 5/8 (seed=2024)...\n",
      "  Training ensemble model 6/8 (seed=2025)...\n",
      "  Training ensemble model 7/8 (seed=3141)...\n",
      "  Training ensemble model 8/8 (seed=9876)...\n",
      "\n",
      "Test prediction confidence statistics:\n",
      "  Mean: 0.8872\n",
      "  Median: 0.9577\n",
      "  Min: 0.2676\n",
      "  Max: 1.0000\n",
      "\n",
      "Test ensemble agreement statistics:\n",
      "  Mean agreement: 0.9861\n",
      "  High agreement (>0.8): 12674 samples\n",
      "  Low agreement (<0.5): 25 samples\n",
      "\n",
      "Test predicted class distribution:\n",
      "  Class 1: 4424 samples (33.82%)\n",
      "  Class 2: 3014 samples (23.04%)\n",
      "  Class 3: 3942 samples (30.13%)\n",
      "  Class 4: 1702 samples (13.01%)\n",
      "\n",
      "Class distribution comparison (Train → Test):\n",
      "  Class 1: 32.1% → 33.8% (Δ +1.7%)\n",
      "  Class 2: 22.2% → 23.0% (Δ +0.9%)\n",
      "  Class 3: 30.7% → 30.1% (Δ -0.6%)\n",
      "  Class 4: 15.0% → 13.0% (Δ -2.0%)\n",
      "\n",
      "✓ Test predictions saved to 'testLabel_xgboost.txt'\n",
      "✓ Confidence metrics saved to 'testLabel_xgboost_confidence.txt'\n",
      "\n",
      "================================================================================\n",
      "[9/9] Generating predictions for BLIND dataset...\n",
      "================================================================================\n",
      "\n",
      "⚠️  'blindData.txt' not found - skipping blind data prediction\n",
      "\n",
      "================================================================================\n",
      "✓ ALL PREDICTIONS COMPLETED SUCCESSFULLY\n",
      "================================================================================\n",
      "\n",
      "Files generated:\n",
      "  1. testLabel_xgboost.txt (13082 predictions)\n",
      "  2. testLabel_xgboost_confidence.txt (test confidence scores)\n",
      "\n",
      "Model Performance Summary:\n",
      "  - Algorithm: XGBoost (Noise-Robust)\n",
      "  - Ensemble size: 8 models\n",
      "  - Expected validation accuracy: 0.9111 ± 0.0061\n",
      "  - Expected macro-average AUC: 0.9871\n",
      "  - Best configuration: Config 3\n",
      "  - Noise resistance features: gamma, min_child_weight, regularization\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"XGBOOST MULTI-CLASS CLASSIFICATION (NOISE-ROBUST)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load data\n",
    "# -----------------------------\n",
    "print(\"\\n[1/8] Loading data...\")\n",
    "X = pd.read_csv('trainingData.txt', header=None)\n",
    "y = pd.read_csv('trainingTruth.txt', header=None, names=['label']).squeeze()\n",
    "test_data = pd.read_csv('testData.txt', header=None)\n",
    "\n",
    "print(f\"Training data shape: {X.shape}\")\n",
    "print(f\"Test data shape: {test_data.shape}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Data Preprocessing\n",
    "# -----------------------------\n",
    "print(\"\\n[2/8] Preprocessing data...\")\n",
    "\n",
    "# Replace empty strings with NaN and convert to numeric\n",
    "X = X.replace('', np.nan).apply(pd.to_numeric, errors='coerce')\n",
    "test_data = test_data.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Remove rows where y is null\n",
    "valid_mask = ~y.isna()\n",
    "X = X[valid_mask].reset_index(drop=True)\n",
    "y = y[valid_mask].reset_index(drop=True)\n",
    "\n",
    "print(f\"After cleaning: {X.shape[0]} samples, {X.shape[1]} features\")\n",
    "\n",
    "# Analyze missing data\n",
    "missing_percentage = (X.isna().sum() / len(X)) * 100\n",
    "features_with_missing = (missing_percentage > 0).sum()\n",
    "print(f\"Features with missing values: {features_with_missing}/{X.shape[1]}\")\n",
    "if features_with_missing > 0:\n",
    "    print(f\"  Max missing %: {missing_percentage.max():.2f}%\")\n",
    "    print(f\"  Mean missing %: {missing_percentage[missing_percentage > 0].mean():.2f}%\")\n",
    "\n",
    "# Check class distribution\n",
    "print(\"\\nClass distribution:\")\n",
    "class_counts = y.value_counts().sort_index()\n",
    "for cls in class_counts.index:\n",
    "    print(f\"  Class {int(cls)}: {class_counts[cls]} samples ({100*class_counts[cls]/len(y):.2f}%)\")\n",
    "\n",
    "# Check for class imbalance\n",
    "is_imbalanced = (class_counts.max() / class_counts.min()) > 1.5\n",
    "if is_imbalanced:\n",
    "    print(\"⚠️  Dataset appears imbalanced - will compute class weights\")\n",
    "\n",
    "# Labels to zero-based for XGBoost\n",
    "y = y - 1\n",
    "\n",
    "# Calculate class weights if imbalanced\n",
    "if is_imbalanced:\n",
    "    class_weights = len(y) / (4 * np.bincount(y.astype(int)))\n",
    "    sample_weights = np.array([class_weights[int(label)] for label in y])\n",
    "    print(f\"Class weights: {class_weights}\")\n",
    "else:\n",
    "    sample_weights = None\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Imputation\n",
    "# -----------------------------\n",
    "print(\"\\n[3/8] Applying median imputation...\")\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "test_imputed = imputer.transform(test_data)\n",
    "\n",
    "print(f\"Feature count: {X_imputed.shape[1]}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. XGBoost Hyperparameter Configurations\n",
    "# -----------------------------\n",
    "print(\"\\n[4/8] Configuring XGBoost parameters (noise-robust)...\")\n",
    "\n",
    "# XGBoost parameters optimized for noisy data:\n",
    "# - max_depth: Limited depth prevents overfitting to noise\n",
    "# - min_child_weight: Higher values prevent learning from noisy samples\n",
    "# - subsample & colsample_bytree: Adds randomness to combat noise\n",
    "# - gamma: Minimum loss reduction (prevents weak splits)\n",
    "# - reg_alpha & reg_lambda: L1 and L2 regularization\n",
    "\n",
    "param_configs = [\n",
    "    {\n",
    "        'objective': 'multi:softprob',\n",
    "        'num_class': 4,\n",
    "        'max_depth': 7,\n",
    "        'learning_rate': 0.03,\n",
    "        'min_child_weight': 30,  # High for noise resistance\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'colsample_bylevel': 0.8,\n",
    "        'gamma': 0.1,  # Minimum loss reduction\n",
    "        'reg_alpha': 1.0,  # L1 regularization\n",
    "        'reg_lambda': 1.5,  # L2 regularization\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'seed': 42,\n",
    "        'tree_method': 'hist',\n",
    "        'verbosity': 0\n",
    "    },\n",
    "    {\n",
    "        'objective': 'multi:softprob',\n",
    "        'num_class': 4,\n",
    "        'max_depth': 6,\n",
    "        'learning_rate': 0.02,\n",
    "        'min_child_weight': 40,\n",
    "        'subsample': 0.75,\n",
    "        'colsample_bytree': 0.75,\n",
    "        'colsample_bylevel': 0.75,\n",
    "        'gamma': 0.15,\n",
    "        'reg_alpha': 1.5,\n",
    "        'reg_lambda': 2.0,\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'seed': 123,\n",
    "        'tree_method': 'hist',\n",
    "        'verbosity': 0\n",
    "    },\n",
    "    {\n",
    "        'objective': 'multi:softprob',\n",
    "        'num_class': 4,\n",
    "        'max_depth': 8,\n",
    "        'learning_rate': 0.04,\n",
    "        'min_child_weight': 25,\n",
    "        'subsample': 0.85,\n",
    "        'colsample_bytree': 0.85,\n",
    "        'colsample_bylevel': 0.85,\n",
    "        'gamma': 0.05,\n",
    "        'reg_alpha': 0.5,\n",
    "        'reg_lambda': 1.0,\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'seed': 456,\n",
    "        'tree_method': 'hist',\n",
    "        'verbosity': 0\n",
    "    },\n",
    "    {\n",
    "        'objective': 'multi:softprob',\n",
    "        'num_class': 4,\n",
    "        'max_depth': 7,\n",
    "        'learning_rate': 0.025,\n",
    "        'min_child_weight': 35,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'colsample_bylevel': 0.8,\n",
    "        'gamma': 0.12,\n",
    "        'reg_alpha': 1.2,\n",
    "        'reg_lambda': 1.8,\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'seed': 789,\n",
    "        'tree_method': 'hist',\n",
    "        'verbosity': 0\n",
    "    }\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Cross-Validation Training\n",
    "# -----------------------------\n",
    "print(\"\\n[5/8] Training with 5-fold cross-validation...\")\n",
    "\n",
    "n_folds = 5\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "all_config_scores = []\n",
    "\n",
    "for config_idx, params in enumerate(param_configs):\n",
    "    print(f\"\\n--- Configuration {config_idx + 1}/{len(param_configs)} ---\")\n",
    "    print(f\"LR: {params['learning_rate']}, Depth: {params['max_depth']}, \"\n",
    "          f\"Min_child: {params['min_child_weight']}, Gamma: {params['gamma']}\")\n",
    "    \n",
    "    fold_scores = []\n",
    "    fold_models = []\n",
    "    fold_best_iterations = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X_imputed, y)):\n",
    "        X_train, X_val = X_imputed[train_idx], X_imputed[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        # Create DMatrix with sample weights if available\n",
    "        if sample_weights is not None:\n",
    "            dtrain = xgb.DMatrix(X_train, label=y_train, weight=sample_weights[train_idx])\n",
    "            dval = xgb.DMatrix(X_val, label=y_val, weight=sample_weights[val_idx])\n",
    "        else:\n",
    "            dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "            dval = xgb.DMatrix(X_val, label=y_val)\n",
    "        \n",
    "        # Train model\n",
    "        evals = [(dval, 'eval')]\n",
    "        evals_result = {}\n",
    "        \n",
    "        model = xgb.train(\n",
    "            params,\n",
    "            dtrain,\n",
    "            num_boost_round=1500,\n",
    "            evals=evals,\n",
    "            early_stopping_rounds=100,\n",
    "            evals_result=evals_result,\n",
    "            verbose_eval=False\n",
    "        )\n",
    "        \n",
    "        # Validate\n",
    "        y_val_pred = model.predict(dval)\n",
    "        y_val_pred_labels = np.argmax(y_val_pred, axis=1)\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_labels)\n",
    "        \n",
    "        fold_scores.append(accuracy)\n",
    "        fold_models.append(model)\n",
    "        fold_best_iterations.append(model.best_iteration)\n",
    "        \n",
    "        print(f\"  Fold {fold + 1}: Accuracy = {accuracy:.4f}, Best iteration = {model.best_iteration}\")\n",
    "    \n",
    "    # Calculate average CV score\n",
    "    avg_score = np.mean(fold_scores)\n",
    "    std_score = np.std(fold_scores)\n",
    "    avg_best_iter = int(np.mean(fold_best_iterations))\n",
    "    print(f\"  → CV Score: {avg_score:.4f} ± {std_score:.4f}\")\n",
    "    print(f\"  → Avg best iteration: {avg_best_iter}\")\n",
    "    \n",
    "    all_config_scores.append((avg_score, std_score, config_idx, fold_models, avg_best_iter))\n",
    "\n",
    "# Select best configuration\n",
    "best_score, best_std, best_config_idx, best_fold_models, best_avg_iter = max(all_config_scores, key=lambda x: x[0])\n",
    "best_params = param_configs[best_config_idx]\n",
    "\n",
    "print(f\"\\n✓ Best configuration: Config {best_config_idx + 1}\")\n",
    "print(f\"  CV Score: {best_score:.4f} ± {best_std:.4f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Validation Metrics\n",
    "# -----------------------------\n",
    "print(\"\\n[6/8] Detailed validation metrics...\")\n",
    "\n",
    "all_val_preds = []\n",
    "all_val_true = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_imputed, y)):\n",
    "    X_val = X_imputed[val_idx]\n",
    "    y_val = y.iloc[val_idx]\n",
    "    \n",
    "    model = best_fold_models[fold]\n",
    "    dval = xgb.DMatrix(X_val)\n",
    "    y_val_pred = model.predict(dval)\n",
    "    \n",
    "    all_val_preds.append(y_val_pred)\n",
    "    all_val_true.extend(y_val.values)\n",
    "\n",
    "all_val_preds = np.vstack(all_val_preds)\n",
    "all_val_true = np.array(all_val_true)\n",
    "\n",
    "val_pred_labels = np.argmax(all_val_preds, axis=1)\n",
    "accuracy = accuracy_score(all_val_true, val_pred_labels)\n",
    "\n",
    "print(f\"\\nOverall Validation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nClass-wise AUC scores:\")\n",
    "auc_scores = []\n",
    "for i in range(4):\n",
    "    y_true_bin = (all_val_true == i).astype(int)\n",
    "    auc = roc_auc_score(y_true_bin, all_val_preds[:, i])\n",
    "    auc_scores.append(auc)\n",
    "    print(f\"  Class {i+1} AUC: {auc:.4f}\")\n",
    "\n",
    "macro_auc = np.mean(auc_scores)\n",
    "print(f\"  Macro-average AUC: {macro_auc:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_val_true, val_pred_labels, \n",
    "                          target_names=[f'Class {i+1}' for i in range(4)],\n",
    "                          digits=4))\n",
    "\n",
    "# -----------------------------\n",
    "# 7. Feature Importance\n",
    "# -----------------------------\n",
    "print(\"\\n[7/8] Analyzing feature importance...\")\n",
    "\n",
    "# Get feature importance from first model (using gain)\n",
    "importance = best_fold_models[0].get_score(importance_type='gain')\n",
    "importance_dict = {int(k.replace('f', '')): v for k, v in importance.items()}\n",
    "\n",
    "# Create full importance array (including zero-importance features)\n",
    "full_importance = np.zeros(X_imputed.shape[1])\n",
    "for idx, val in importance_dict.items():\n",
    "    full_importance[idx] = val\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature_idx': range(len(full_importance)),\n",
    "    'importance': full_importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 20 most important features:\")\n",
    "for idx, row in importance_df.head(20).iterrows():\n",
    "    print(f\"  Feature {int(row['feature_idx'])}: {row['importance']:.2f}\")\n",
    "\n",
    "zero_importance = (full_importance == 0).sum()\n",
    "if zero_importance > 0:\n",
    "    print(f\"\\n⚠️  {zero_importance} features have zero importance (likely noise)\")\n",
    "\n",
    "# -----------------------------\n",
    "# 8. Ensemble Prediction on Test Set\n",
    "# -----------------------------\n",
    "print(\"\\n[8/8] Generating ensemble predictions on test set...\")\n",
    "\n",
    "ensemble_test_preds = []\n",
    "seeds = [42, 123, 456, 789, 2024, 2025, 3141, 9876]\n",
    "\n",
    "for seed_idx, seed in enumerate(seeds):\n",
    "    print(f\"  Training ensemble model {seed_idx + 1}/{len(seeds)} (seed={seed})...\")\n",
    "    \n",
    "    params_with_seed = best_params.copy()\n",
    "    params_with_seed['seed'] = seed\n",
    "    \n",
    "    # Create DMatrix\n",
    "    if sample_weights is not None:\n",
    "        dtrain_full = xgb.DMatrix(X_imputed, label=y, weight=sample_weights)\n",
    "    else:\n",
    "        dtrain_full = xgb.DMatrix(X_imputed, label=y)\n",
    "    \n",
    "    dtest = xgb.DMatrix(test_imputed)\n",
    "    \n",
    "    model = xgb.train(\n",
    "        params_with_seed,\n",
    "        dtrain_full,\n",
    "        num_boost_round=best_avg_iter,\n",
    "        verbose_eval=False\n",
    "    )\n",
    "    \n",
    "    test_pred = model.predict(dtest)\n",
    "    ensemble_test_preds.append(test_pred)\n",
    "\n",
    "# Average ensemble predictions\n",
    "test_pred_final = np.mean(ensemble_test_preds, axis=0)\n",
    "test_labels = np.argmax(test_pred_final, axis=1) + 1\n",
    "\n",
    "# Calculate confidence metrics\n",
    "prediction_confidence = np.max(test_pred_final, axis=1)\n",
    "ensemble_agreement = np.array([\n",
    "    np.mean([np.argmax(pred[i]) == np.argmax(test_pred_final[i]) \n",
    "             for pred in ensemble_test_preds])\n",
    "    for i in range(len(test_pred_final))\n",
    "])\n",
    "\n",
    "print(f\"\\nTest prediction confidence statistics:\")\n",
    "print(f\"  Mean: {prediction_confidence.mean():.4f}\")\n",
    "print(f\"  Median: {np.median(prediction_confidence):.4f}\")\n",
    "print(f\"  Min: {prediction_confidence.min():.4f}\")\n",
    "print(f\"  Max: {prediction_confidence.max():.4f}\")\n",
    "\n",
    "print(f\"\\nTest ensemble agreement statistics:\")\n",
    "print(f\"  Mean agreement: {ensemble_agreement.mean():.4f}\")\n",
    "print(f\"  High agreement (>0.8): {(ensemble_agreement > 0.8).sum()} samples\")\n",
    "print(f\"  Low agreement (<0.5): {(ensemble_agreement < 0.5).sum()} samples\")\n",
    "\n",
    "# Show class distribution\n",
    "print(\"\\nTest predicted class distribution:\")\n",
    "pred_counts = pd.Series(test_labels).value_counts().sort_index()\n",
    "for cls in pred_counts.index:\n",
    "    print(f\"  Class {int(cls)}: {pred_counts[cls]} samples ({100*pred_counts[cls]/len(test_labels):.2f}%)\")\n",
    "\n",
    "# Compare with training\n",
    "print(\"\\nClass distribution comparison (Train → Test):\")\n",
    "for cls in sorted(class_counts.index):\n",
    "    train_pct = 100 * class_counts[cls] / len(y)\n",
    "    test_pct = 100 * pred_counts.get(cls, 0) / len(test_labels)\n",
    "    diff = test_pct - train_pct\n",
    "    print(f\"  Class {int(cls)}: {train_pct:.1f}% → {test_pct:.1f}% (Δ {diff:+.1f}%)\")\n",
    "\n",
    "# -----------------------------\n",
    "# 9. Save Test Results\n",
    "# -----------------------------\n",
    "output = np.column_stack([test_pred_final, test_labels])\n",
    "np.savetxt('testLabel_xgboost.txt', output, \n",
    "           fmt='%.6f\\t%.6f\\t%.6f\\t%.6f\\t%d', \n",
    "           delimiter='\\t')\n",
    "\n",
    "np.savetxt('testLabel_xgboost_confidence.txt', \n",
    "           np.column_stack([test_labels, prediction_confidence, ensemble_agreement]),\n",
    "           fmt='%d\\t%.6f\\t%.6f',\n",
    "           header='predicted_label\\tconfidence\\tensemble_agreement',\n",
    "           comments='')\n",
    "\n",
    "print(f\"\\n✓ Test predictions saved to 'testLabel_xgboost.txt'\")\n",
    "print(f\"✓ Confidence metrics saved to 'testLabel_xgboost_confidence.txt'\")\n",
    "\n",
    "# -----------------------------\n",
    "# 10. Blind Data Prediction\n",
    "# -----------------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"[9/9] Generating predictions for BLIND dataset...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "try:\n",
    "    blind_data = pd.read_csv('blindData.txt', header=None)\n",
    "    print(f\"\\nBlind data shape: {blind_data.shape}\")\n",
    "    \n",
    "    blind_data = blind_data.apply(pd.to_numeric, errors='coerce')\n",
    "    blind_imputed = imputer.transform(blind_data)\n",
    "    \n",
    "    print(f\"Preprocessed blind data shape: {blind_imputed.shape}\")\n",
    "    print(f\"\\nGenerating ensemble predictions with {len(seeds)} models...\")\n",
    "    \n",
    "    ensemble_blind_preds = []\n",
    "    \n",
    "    for seed_idx, seed in enumerate(seeds):\n",
    "        print(f\"  Model {seed_idx + 1}/{len(seeds)}...\", end='\\r')\n",
    "        \n",
    "        params_with_seed = best_params.copy()\n",
    "        params_with_seed['seed'] = seed\n",
    "        \n",
    "        if sample_weights is not None:\n",
    "            dtrain_full = xgb.DMatrix(X_imputed, label=y, weight=sample_weights)\n",
    "        else:\n",
    "            dtrain_full = xgb.DMatrix(X_imputed, label=y)\n",
    "        \n",
    "        dblind = xgb.DMatrix(blind_imputed)\n",
    "        \n",
    "        model = xgb.train(\n",
    "            params_with_seed,\n",
    "            dtrain_full,\n",
    "            num_boost_round=best_avg_iter,\n",
    "            verbose_eval=False\n",
    "        )\n",
    "        \n",
    "        blind_pred = model.predict(dblind)\n",
    "        ensemble_blind_preds.append(blind_pred)\n",
    "    \n",
    "    print(f\"  Completed all {len(seeds)} models    \")\n",
    "    \n",
    "    # Average predictions\n",
    "    blind_pred_final = np.mean(ensemble_blind_preds, axis=0)\n",
    "    blind_labels = np.argmax(blind_pred_final, axis=1) + 1\n",
    "    \n",
    "    # Calculate metrics\n",
    "    blind_confidence = np.max(blind_pred_final, axis=1)\n",
    "    blind_agreement = np.array([\n",
    "        np.mean([np.argmax(pred[i]) == np.argmax(blind_pred_final[i]) \n",
    "                 for pred in ensemble_blind_preds])\n",
    "        for i in range(len(blind_pred_final))\n",
    "    ])\n",
    "    \n",
    "    print(f\"\\nBlind prediction confidence statistics:\")\n",
    "    print(f\"  Mean: {blind_confidence.mean():.4f}\")\n",
    "    print(f\"  Median: {np.median(blind_confidence):.4f}\")\n",
    "    print(f\"  Min: {blind_confidence.min():.4f}\")\n",
    "    print(f\"  Max: {blind_confidence.max():.4f}\")\n",
    "    \n",
    "    print(f\"\\nBlind ensemble agreement statistics:\")\n",
    "    print(f\"  Mean agreement: {blind_agreement.mean():.4f}\")\n",
    "    print(f\"  High agreement (>0.8): {(blind_agreement > 0.8).sum()} samples\")\n",
    "    print(f\"  Low agreement (<0.5): {(blind_agreement < 0.5).sum()} samples\")\n",
    "    \n",
    "    print(\"\\nBlind predicted class distribution:\")\n",
    "    blind_pred_counts = pd.Series(blind_labels).value_counts().sort_index()\n",
    "    for cls in blind_pred_counts.index:\n",
    "        print(f\"  Class {int(cls)}: {blind_pred_counts[cls]} samples ({100*blind_pred_counts[cls]/len(blind_labels):.2f}%)\")\n",
    "    \n",
    "    print(\"\\nClass distribution comparison (Train → Test → Blind):\")\n",
    "    for cls in sorted(class_counts.index):\n",
    "        train_pct = 100 * class_counts[cls] / len(y)\n",
    "        test_pct = 100 * pred_counts.get(cls, 0) / len(test_labels)\n",
    "        blind_pct = 100 * blind_pred_counts.get(cls, 0) / len(blind_labels)\n",
    "        print(f\"  Class {int(cls)}: {train_pct:.1f}% → {test_pct:.1f}% → {blind_pct:.1f}%\")\n",
    "    \n",
    "    # Save predictions\n",
    "    blind_output = np.column_stack([blind_pred_final, blind_labels])\n",
    "    np.savetxt('blindLabel_xgboost.txt', blind_output, \n",
    "               fmt='%.6f\\t%.6f\\t%.6f\\t%.6f\\t%d', \n",
    "               delimiter='\\t')\n",
    "    \n",
    "    np.savetxt('blindLabel_xgboost_confidence.txt', \n",
    "               np.column_stack([blind_labels, blind_confidence, blind_agreement]),\n",
    "               fmt='%d\\t%.6f\\t%.6f',\n",
    "               header='predicted_label\\tconfidence\\tensemble_agreement',\n",
    "               comments='')\n",
    "    \n",
    "    print(f\"\\n✓ Blind predictions saved to 'blindLabel_xgboost.txt'\")\n",
    "    print(f\"✓ Blind confidence metrics saved to 'blindLabel_xgboost_confidence.txt'\")\n",
    "    print(f\"  - {len(blind_labels)} predictions generated\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"\\n⚠️  'blindData.txt' not found - skipping blind data prediction\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n⚠️  Error processing blind data: {e}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Final Summary\n",
    "# -----------------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✓ ALL PREDICTIONS COMPLETED SUCCESSFULLY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nFiles generated:\")\n",
    "print(f\"  1. testLabel_xgboost.txt ({len(test_labels)} predictions)\")\n",
    "print(f\"  2. testLabel_xgboost_confidence.txt (test confidence scores)\")\n",
    "try:\n",
    "    print(f\"  3. blindLabel_xgboost.txt ({len(blind_labels)} predictions)\")\n",
    "    print(f\"  4. blindLabel_xgboost_confidence.txt (blind confidence scores)\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(f\"\\nModel Performance Summary:\")\n",
    "print(f\"  - Algorithm: XGBoost (Noise-Robust)\")\n",
    "print(f\"  - Ensemble size: {len(seeds)} models\")\n",
    "print(f\"  - Expected validation accuracy: {best_score:.4f} ± {best_std:.4f}\")\n",
    "print(f\"  - Expected macro-average AUC: {macro_auc:.4f}\")\n",
    "print(f\"  - Best configuration: Config {best_config_idx + 1}\")\n",
    "print(f\"  - Noise resistance features: gamma, min_child_weight, regularization\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39584b09-adfa-447c-85a0-31ad1f790c96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (py39)",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
