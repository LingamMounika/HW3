{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0038a90e-0063-45bc-9545-9674c7a1730a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ENHANCED LIGHTGBM MULTI-CLASS CLASSIFICATION (NOISE-ROBUST)\n",
      "================================================================================\n",
      "\n",
      "[1/9] Loading data...\n",
      "Training data shape: (27617, 411)\n",
      "Test data shape: (13082, 411)\n",
      "\n",
      "[2/9] Preprocessing data (noise-robust approach)...\n",
      "After cleaning: 27617 samples, 411 features\n",
      "Features with missing values: 1/411\n",
      "  Max missing %: 0.50%\n",
      "  Mean missing %: 0.50%\n",
      "\n",
      "Class distribution:\n",
      "label\n",
      "1    8874\n",
      "2    6127\n",
      "3    8483\n",
      "4    4133\n",
      "Name: count, dtype: int64\n",
      "  Class 1: 8874 samples (32.13%)\n",
      "  Class 2: 6127 samples (22.19%)\n",
      "  Class 3: 8483 samples (30.72%)\n",
      "  Class 4: 4133 samples (14.97%)\n",
      "⚠️  Dataset appears imbalanced - using balanced weights\n",
      "\n",
      "[3/9] Applying noise-robust imputation...\n",
      "Final feature count: 411\n",
      "\n",
      "[4/9] Configuring noise-robust hyperparameters...\n",
      "\n",
      "[5/9] Training with 5-fold cross-validation...\n",
      "\n",
      "--- Configuration 1/4 ---\n",
      "LR: 0.02, Leaves: 31, Depth: 7, Min_data: 30\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1497]\tvalid_0's multi_logloss: 0.252705\n",
      "  Fold 1: Accuracy = 0.9131, Best iteration = 1497\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1500]\tvalid_0's multi_logloss: 0.278793\n",
      "  Fold 2: Accuracy = 0.8950, Best iteration = 1500\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1500]\tvalid_0's multi_logloss: 0.258507\n",
      "  Fold 3: Accuracy = 0.9069, Best iteration = 1500\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1500]\tvalid_0's multi_logloss: 0.277402\n",
      "  Fold 4: Accuracy = 0.9057, Best iteration = 1500\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1500]\tvalid_0's multi_logloss: 0.28106\n",
      "  Fold 5: Accuracy = 0.8953, Best iteration = 1500\n",
      "  → CV Score: 0.9032 ± 0.0070\n",
      "\n",
      "--- Configuration 2/4 ---\n",
      "LR: 0.03, Leaves: 50, Depth: 8, Min_data: 25\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1292]\tvalid_0's multi_logloss: 0.232381\n",
      "  Fold 1: Accuracy = 0.9129, Best iteration = 1292\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1260]\tvalid_0's multi_logloss: 0.25841\n",
      "  Fold 2: Accuracy = 0.9050, Best iteration = 1260\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1296]\tvalid_0's multi_logloss: 0.235002\n",
      "  Fold 3: Accuracy = 0.9127, Best iteration = 1296\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1185]\tvalid_0's multi_logloss: 0.261134\n",
      "  Fold 4: Accuracy = 0.9107, Best iteration = 1185\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1196]\tvalid_0's multi_logloss: 0.266102\n",
      "  Fold 5: Accuracy = 0.9044, Best iteration = 1196\n",
      "  → CV Score: 0.9092 ± 0.0037\n",
      "\n",
      "--- Configuration 3/4 ---\n",
      "LR: 0.025, Leaves: 40, Depth: 9, Min_data: 20\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1477]\tvalid_0's multi_logloss: 0.223748\n",
      "  Fold 1: Accuracy = 0.9185, Best iteration = 1477\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1483]\tvalid_0's multi_logloss: 0.252229\n",
      "  Fold 2: Accuracy = 0.9037, Best iteration = 1483\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1381]\tvalid_0's multi_logloss: 0.22882\n",
      "  Fold 3: Accuracy = 0.9167, Best iteration = 1381\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1401]\tvalid_0's multi_logloss: 0.255749\n",
      "  Fold 4: Accuracy = 0.9115, Best iteration = 1401\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1372]\tvalid_0's multi_logloss: 0.257361\n",
      "  Fold 5: Accuracy = 0.9033, Best iteration = 1372\n",
      "  → CV Score: 0.9107 ± 0.0064\n",
      "\n",
      "--- Configuration 4/4 ---\n",
      "LR: 0.015, Leaves: 25, Depth: 6, Min_data: 40\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1500]\tvalid_0's multi_logloss: 0.295618\n",
      "  Fold 1: Accuracy = 0.9028, Best iteration = 1500\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1500]\tvalid_0's multi_logloss: 0.318312\n",
      "  Fold 2: Accuracy = 0.8850, Best iteration = 1500\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1500]\tvalid_0's multi_logloss: 0.3023\n",
      "  Fold 3: Accuracy = 0.8972, Best iteration = 1500\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1500]\tvalid_0's multi_logloss: 0.31834\n",
      "  Fold 4: Accuracy = 0.8935, Best iteration = 1500\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1500]\tvalid_0's multi_logloss: 0.318853\n",
      "  Fold 5: Accuracy = 0.8867, Best iteration = 1500\n",
      "  → CV Score: 0.8930 ± 0.0066\n",
      "\n",
      "✓ Best configuration: Config 3\n",
      "  CV Score: 0.9107 ± 0.0064\n",
      "\n",
      "[6/9] Detailed validation metrics...\n",
      "\n",
      "Overall Validation Accuracy: 0.9107\n",
      "\n",
      "Class-wise AUC scores:\n",
      "  Class 1 AUC: 0.9924\n",
      "  Class 2 AUC: 0.9895\n",
      "  Class 3 AUC: 0.9907\n",
      "  Class 4 AUC: 0.9775\n",
      "  Macro-average AUC: 0.9875\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 1     0.9108    0.9733    0.9410      8874\n",
      "     Class 2     0.8634    0.9385    0.8994      6127\n",
      "     Class 3     0.9513    0.9283    0.9397      8483\n",
      "     Class 4     0.9043    0.6992    0.7886      4133\n",
      "\n",
      "    accuracy                         0.9107     27617\n",
      "   macro avg     0.9074    0.8848    0.8922     27617\n",
      "weighted avg     0.9117    0.9107    0.9086     27617\n",
      "\n",
      "\n",
      "[7/9] Analyzing feature importance...\n",
      "\n",
      "Top 20 most important features:\n",
      "  Feature 85: 39062.73\n",
      "  Feature 86: 22369.10\n",
      "  Feature 356: 20832.18\n",
      "  Feature 357: 20252.45\n",
      "  Feature 336: 18016.89\n",
      "  Feature 84: 17270.04\n",
      "  Feature 124: 17036.32\n",
      "  Feature 337: 15020.47\n",
      "  Feature 165: 14701.15\n",
      "  Feature 205: 14333.21\n",
      "  Feature 185: 14053.92\n",
      "  Feature 225: 13179.53\n",
      "  Feature 143: 12654.12\n",
      "  Feature 346: 12559.45\n",
      "  Feature 355: 12419.54\n",
      "  Feature 94: 11890.40\n",
      "  Feature 105: 11543.25\n",
      "  Feature 354: 11509.48\n",
      "  Feature 66: 11159.13\n",
      "  Feature 144: 10714.51\n",
      "\n",
      "[8/9] Generating ensemble predictions on test set...\n",
      "  Training ensemble model 1/8 (seed=42)...\n",
      "  Training ensemble model 2/8 (seed=123)...\n",
      "  Training ensemble model 3/8 (seed=456)...\n",
      "  Training ensemble model 4/8 (seed=789)...\n",
      "  Training ensemble model 5/8 (seed=2024)...\n",
      "  Training ensemble model 6/8 (seed=2025)...\n",
      "  Training ensemble model 7/8 (seed=3141)...\n",
      "  Training ensemble model 8/8 (seed=9876)...\n",
      "\n",
      "Test prediction confidence statistics:\n",
      "  Mean: 0.9040\n",
      "  Median: 0.9756\n",
      "  Min: 0.3050\n",
      "  Max: 1.0000\n",
      "\n",
      "Test ensemble agreement statistics:\n",
      "  Mean agreement: 0.9869\n",
      "  High agreement (>0.8): 12699 samples\n",
      "  Low agreement (<0.5): 19 samples\n",
      "\n",
      "Test predicted class distribution:\n",
      "  Class 1: 4451 samples (34.02%)\n",
      "  Class 2: 3081 samples (23.55%)\n",
      "  Class 3: 3934 samples (30.07%)\n",
      "  Class 4: 1616 samples (12.35%)\n",
      "\n",
      "Class distribution comparison (Training → Test):\n",
      "  Class 1: 32.1% → 34.0% (Δ +1.9%)\n",
      "  Class 2: 22.2% → 23.6% (Δ +1.4%)\n",
      "  Class 3: 30.7% → 30.1% (Δ -0.6%)\n",
      "  Class 4: 15.0% → 12.4% (Δ -2.6%)\n",
      "\n",
      "✓ Test predictions saved to 'testLabel_lightgbm.txt'\n",
      "✓ Test confidence metrics saved to 'testLabel_confidence.txt'\n",
      "  - 13082 predictions generated\n",
      "\n",
      "[9/9] Checking for blind data...\n",
      "✓ Blind data found: (31979, 411)\n",
      "\n",
      "Preprocessing blind data...\n",
      "✓ Blind data imputed: (31979, 411)\n",
      "\n",
      "Generating ensemble predictions for blind data...\n",
      "  Predicting with ensemble model 1/8 (seed=42)...\n",
      "  Predicting with ensemble model 2/8 (seed=123)...\n",
      "  Predicting with ensemble model 3/8 (seed=456)...\n",
      "  Predicting with ensemble model 4/8 (seed=789)...\n",
      "  Predicting with ensemble model 5/8 (seed=2024)...\n",
      "  Predicting with ensemble model 6/8 (seed=2025)...\n",
      "  Predicting with ensemble model 7/8 (seed=3141)...\n",
      "  Predicting with ensemble model 8/8 (seed=9876)...\n",
      "\n",
      "Blind data prediction confidence statistics:\n",
      "  Mean: 0.9056\n",
      "  Median: 0.9761\n",
      "  Min: 0.2654\n",
      "  Max: 1.0000\n",
      "\n",
      "Blind data ensemble agreement statistics:\n",
      "  Mean agreement: 0.9867\n",
      "  High agreement (>0.8): 31018 samples\n",
      "  Low agreement (<0.5): 57 samples\n",
      "\n",
      "Blind data predicted class distribution:\n",
      "  Class 1: 10887 samples (34.04%)\n",
      "  Class 2: 7637 samples (23.88%)\n",
      "  Class 3: 9596 samples (30.01%)\n",
      "  Class 4: 3859 samples (12.07%)\n",
      "\n",
      "Class distribution comparison (Training → Test → Blind):\n",
      "  Class 1: 32.1% → 34.0% → 34.0%\n",
      "  Class 2: 22.2% → 23.6% → 23.9%\n",
      "  Class 3: 30.7% → 30.1% → 30.0%\n",
      "  Class 4: 15.0% → 12.4% → 12.1%\n",
      "\n",
      "✓ Blind predictions saved to 'blindLabel_lightgbm.txt'\n",
      "✓ Blind confidence metrics saved to 'blindLabel_confidence.txt'\n",
      "  - 31979 predictions generated\n",
      "\n",
      "================================================================================\n",
      "✓ COMPLETED SUCCESSFULLY\n",
      "================================================================================\n",
      "\n",
      "Summary of outputs:\n",
      "  1. Test predictions: testLabel_lightgbm.txt (13082 samples)\n",
      "  2. Test confidence: testLabel_confidence.txt\n",
      "  3. Blind predictions: blindLabel_lightgbm.txt (31979 samples)\n",
      "  4. Blind confidence: blindLabel_confidence.txt\n",
      "\n",
      "Model Performance:\n",
      "  - Cross-validation accuracy: 0.9107 ± 0.0064\n",
      "  - Macro-average AUC: 0.9875\n",
      "  - Ensemble size: 8 models\n",
      "  - Best configuration: Config 3\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from lightgbm.callback import early_stopping, log_evaluation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ENHANCED LIGHTGBM MULTI-CLASS CLASSIFICATION (NOISE-ROBUST)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load data\n",
    "# -----------------------------\n",
    "print(\"\\n[1/9] Loading data...\")\n",
    "X = pd.read_csv('trainingData.txt', header=None)\n",
    "y = pd.read_csv('trainingTruth.txt', header=None, names=['label']).squeeze()\n",
    "test_data = pd.read_csv('testData.txt', header=None)\n",
    "\n",
    "print(f\"Training data shape: {X.shape}\")\n",
    "print(f\"Test data shape: {test_data.shape}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Data Preprocessing (Noise-Aware)\n",
    "# -----------------------------\n",
    "print(\"\\n[2/9] Preprocessing data (noise-robust approach)...\")\n",
    "\n",
    "# Replace empty strings with NaN and convert to numeric\n",
    "X = X.replace('', np.nan).apply(pd.to_numeric, errors='coerce')\n",
    "test_data = test_data.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Remove rows where y is null (align X and y)\n",
    "valid_mask = ~y.isna()\n",
    "X = X[valid_mask].reset_index(drop=True)\n",
    "y = y[valid_mask].reset_index(drop=True)\n",
    "\n",
    "print(f\"After cleaning: {X.shape[0]} samples, {X.shape[1]} features\")\n",
    "\n",
    "# Analyze missing data in training\n",
    "missing_percentage = (X.isna().sum() / len(X)) * 100\n",
    "features_with_missing = (missing_percentage > 0).sum()\n",
    "print(f\"Features with missing values: {features_with_missing}/{X.shape[1]}\")\n",
    "if features_with_missing > 0:\n",
    "    print(f\"  Max missing %: {missing_percentage.max():.2f}%\")\n",
    "    print(f\"  Mean missing %: {missing_percentage[missing_percentage > 0].mean():.2f}%\")\n",
    "\n",
    "# Check class distribution\n",
    "print(\"\\nClass distribution:\")\n",
    "class_counts = y.value_counts().sort_index()\n",
    "print(class_counts)\n",
    "for cls in class_counts.index:\n",
    "    print(f\"  Class {int(cls)}: {class_counts[cls]} samples ({100*class_counts[cls]/len(y):.2f}%)\")\n",
    "\n",
    "# Check for class imbalance\n",
    "is_imbalanced = (class_counts.max() / class_counts.min()) > 1.5\n",
    "if is_imbalanced:\n",
    "    print(\"⚠️  Dataset appears imbalanced - using balanced weights\")\n",
    "\n",
    "# Labels to zero-based for LightGBM\n",
    "y = y - 1\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Noise-Robust Imputation Strategy\n",
    "# -----------------------------\n",
    "print(\"\\n[3/9] Applying noise-robust imputation...\")\n",
    "\n",
    "# Strategy: Use median imputation for robustness against noise\n",
    "# Median is less sensitive to outliers/noise than mean\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "test_imputed = imputer.transform(test_data)\n",
    "\n",
    "# Optional: Apply RobustScaler for outlier resistance\n",
    "# Note: Tree-based models don't require scaling, but can help with noise\n",
    "# Uncommenting this may help if noise manifests as extreme outliers\n",
    "# scaler = RobustScaler()\n",
    "# X_imputed = scaler.fit_transform(X_imputed)\n",
    "# test_imputed = scaler.transform(test_imputed)\n",
    "\n",
    "print(f\"Final feature count: {X_imputed.shape[1]}\")\n",
    "\n",
    "# Detect potential outliers/noise\n",
    "for i in range(min(5, X_imputed.shape[1])):  # Check first 5 features\n",
    "    q1, q99 = np.percentile(X_imputed[:, i], [1, 99])\n",
    "    outlier_count = np.sum((X_imputed[:, i] < q1) | (X_imputed[:, i] > q99))\n",
    "    if outlier_count > len(X_imputed) * 0.05:\n",
    "        print(f\"  Feature {i}: {outlier_count} potential outliers detected ({100*outlier_count/len(X_imputed):.1f}%)\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Noise-Robust Hyperparameters\n",
    "# -----------------------------\n",
    "print(\"\\n[4/9] Configuring noise-robust hyperparameters...\")\n",
    "\n",
    "# Parameters optimized for noisy data:\n",
    "# - Higher min_data_in_leaf: prevents overfitting to noise\n",
    "# - Lower learning_rate: more gradual learning\n",
    "# - Regularization (lambda_l1, lambda_l2): reduces overfitting\n",
    "# - max_depth limitation: prevents learning noise patterns\n",
    "# - Feature/bagging fraction: adds randomness to combat noise\n",
    "\n",
    "param_configs = [\n",
    "    {\n",
    "        'objective': 'multiclass',\n",
    "        'num_class': 4,\n",
    "        'metric': 'multi_logloss',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'learning_rate': 0.02,\n",
    "        'num_leaves': 31,\n",
    "        'max_depth': 7,\n",
    "        'min_data_in_leaf': 30,  # Higher to resist noise\n",
    "        'feature_fraction': 0.75,  # Lower for more robustness\n",
    "        'bagging_fraction': 0.75,\n",
    "        'bagging_freq': 5,\n",
    "        'lambda_l1': 1.0,  # Strong L1 regularization\n",
    "        'lambda_l2': 1.0,  # Strong L2 regularization\n",
    "        'min_gain_to_split': 0.01,  # Prevent weak splits\n",
    "        'verbose': -1,\n",
    "        'is_unbalance': is_imbalanced,\n",
    "        'seed': 42\n",
    "    },\n",
    "    {\n",
    "        'objective': 'multiclass',\n",
    "        'num_class': 4,\n",
    "        'metric': 'multi_logloss',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'learning_rate': 0.03,\n",
    "        'num_leaves': 50,\n",
    "        'max_depth': 8,\n",
    "        'min_data_in_leaf': 25,\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 4,\n",
    "        'lambda_l1': 0.5,\n",
    "        'lambda_l2': 1.5,\n",
    "        'min_gain_to_split': 0.005,\n",
    "        'verbose': -1,\n",
    "        'is_unbalance': is_imbalanced,\n",
    "        'seed': 123\n",
    "    },\n",
    "    {\n",
    "        'objective': 'multiclass',\n",
    "        'num_class': 4,\n",
    "        'metric': 'multi_logloss',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'learning_rate': 0.025,\n",
    "        'num_leaves': 40,\n",
    "        'max_depth': 9,\n",
    "        'min_data_in_leaf': 20,\n",
    "        'feature_fraction': 0.85,\n",
    "        'bagging_fraction': 0.85,\n",
    "        'bagging_freq': 3,\n",
    "        'lambda_l1': 0.3,\n",
    "        'lambda_l2': 0.7,\n",
    "        'min_gain_to_split': 0.01,\n",
    "        'verbose': -1,\n",
    "        'is_unbalance': is_imbalanced,\n",
    "        'seed': 456\n",
    "    },\n",
    "    {\n",
    "        'objective': 'multiclass',\n",
    "        'num_class': 4,\n",
    "        'metric': 'multi_logloss',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'learning_rate': 0.015,\n",
    "        'num_leaves': 25,\n",
    "        'max_depth': 6,\n",
    "        'min_data_in_leaf': 40,  # Very conservative\n",
    "        'feature_fraction': 0.7,\n",
    "        'bagging_fraction': 0.7,\n",
    "        'bagging_freq': 6,\n",
    "        'lambda_l1': 1.5,\n",
    "        'lambda_l2': 1.5,\n",
    "        'min_gain_to_split': 0.02,\n",
    "        'verbose': -1,\n",
    "        'is_unbalance': is_imbalanced,\n",
    "        'seed': 789\n",
    "    }\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Cross-Validation Training\n",
    "# -----------------------------\n",
    "print(\"\\n[5/9] Training with 5-fold cross-validation...\")\n",
    "\n",
    "n_folds = 5\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Store results for each configuration\n",
    "all_config_scores = []\n",
    "\n",
    "for config_idx, params in enumerate(param_configs):\n",
    "    print(f\"\\n--- Configuration {config_idx + 1}/{len(param_configs)} ---\")\n",
    "    print(f\"LR: {params['learning_rate']}, Leaves: {params['num_leaves']}, \"\n",
    "          f\"Depth: {params['max_depth']}, Min_data: {params['min_data_in_leaf']}\")\n",
    "    \n",
    "    fold_scores = []\n",
    "    fold_models = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X_imputed, y)):\n",
    "        X_train, X_val = X_imputed[train_idx], X_imputed[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        # Create datasets\n",
    "        train_dataset = lgb.Dataset(X_train, label=y_train)\n",
    "        valid_dataset = lgb.Dataset(X_val, label=y_val, reference=train_dataset)\n",
    "        \n",
    "        # Train model with more conservative early stopping\n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_dataset,\n",
    "            num_boost_round=1500,  # More rounds with lower LR\n",
    "            valid_sets=[valid_dataset],\n",
    "            callbacks=[\n",
    "                early_stopping(stopping_rounds=100),  # More patience for noisy data\n",
    "                log_evaluation(period=0)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Validate\n",
    "        y_val_pred = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "        y_val_pred_labels = np.argmax(y_val_pred, axis=1)\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_labels)\n",
    "        \n",
    "        fold_scores.append(accuracy)\n",
    "        fold_models.append(model)\n",
    "        \n",
    "        print(f\"  Fold {fold + 1}: Accuracy = {accuracy:.4f}, Best iteration = {model.best_iteration}\")\n",
    "    \n",
    "    # Calculate average CV score\n",
    "    avg_score = np.mean(fold_scores)\n",
    "    std_score = np.std(fold_scores)\n",
    "    print(f\"  → CV Score: {avg_score:.4f} ± {std_score:.4f}\")\n",
    "    \n",
    "    all_config_scores.append((avg_score, std_score, config_idx, fold_models))\n",
    "\n",
    "# Select best configuration\n",
    "best_score, best_std, best_config_idx, best_fold_models = max(all_config_scores, key=lambda x: x[0])\n",
    "best_params = param_configs[best_config_idx]\n",
    "\n",
    "print(f\"\\n✓ Best configuration: Config {best_config_idx + 1}\")\n",
    "print(f\"  CV Score: {best_score:.4f} ± {best_std:.4f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Validation Metrics\n",
    "# -----------------------------\n",
    "print(\"\\n[6/9] Detailed validation metrics...\")\n",
    "\n",
    "all_val_preds = []\n",
    "all_val_true = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_imputed, y)):\n",
    "    X_val = X_imputed[val_idx]\n",
    "    y_val = y.iloc[val_idx]\n",
    "    \n",
    "    model = best_fold_models[fold]\n",
    "    y_val_pred = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "    \n",
    "    all_val_preds.append(y_val_pred)\n",
    "    all_val_true.extend(y_val.values)\n",
    "\n",
    "all_val_preds = np.vstack(all_val_preds)\n",
    "all_val_true = np.array(all_val_true)\n",
    "\n",
    "val_pred_labels = np.argmax(all_val_preds, axis=1)\n",
    "accuracy = accuracy_score(all_val_true, val_pred_labels)\n",
    "\n",
    "print(f\"\\nOverall Validation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nClass-wise AUC scores:\")\n",
    "auc_scores = []\n",
    "for i in range(4):\n",
    "    y_true_bin = (all_val_true == i).astype(int)\n",
    "    auc = roc_auc_score(y_true_bin, all_val_preds[:, i])\n",
    "    auc_scores.append(auc)\n",
    "    print(f\"  Class {i+1} AUC: {auc:.4f}\")\n",
    "\n",
    "macro_auc = np.mean(auc_scores)\n",
    "print(f\"  Macro-average AUC: {macro_auc:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_val_true, val_pred_labels, \n",
    "                          target_names=[f'Class {i+1}' for i in range(4)],\n",
    "                          digits=4))\n",
    "\n",
    "# -----------------------------\n",
    "# 7. Feature Importance\n",
    "# -----------------------------\n",
    "print(\"\\n[7/9] Analyzing feature importance...\")\n",
    "\n",
    "importance = best_fold_models[0].feature_importance(importance_type='gain')\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature_idx': range(len(importance)),\n",
    "    'importance': importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 20 most important features:\")\n",
    "for idx, row in importance_df.head(20).iterrows():\n",
    "    print(f\"  Feature {int(row['feature_idx'])}: {row['importance']:.2f}\")\n",
    "\n",
    "# Check if some features are being ignored (possible noise features)\n",
    "zero_importance = (importance == 0).sum()\n",
    "if zero_importance > 0:\n",
    "    print(f\"\\n⚠️  {zero_importance} features have zero importance (likely noise)\")\n",
    "\n",
    "# -----------------------------\n",
    "# 8. Ensemble Prediction on Test Set\n",
    "# -----------------------------\n",
    "print(\"\\n[8/9] Generating ensemble predictions on test set...\")\n",
    "\n",
    "# Strategy for noisy data: Use larger ensemble for stability\n",
    "ensemble_test_preds = []\n",
    "\n",
    "# Use best config with different seeds + some diversity\n",
    "seeds = [42, 123, 456, 789, 2024, 2025, 3141, 9876]\n",
    "\n",
    "for seed_idx, seed in enumerate(seeds):\n",
    "    print(f\"  Training ensemble model {seed_idx + 1}/{len(seeds)} (seed={seed})...\")\n",
    "    \n",
    "    params_with_seed = best_params.copy()\n",
    "    params_with_seed['seed'] = seed\n",
    "    \n",
    "    # Use average best iteration from CV\n",
    "    avg_best_iter = int(np.mean([m.best_iteration for m in best_fold_models]))\n",
    "    \n",
    "    full_train = lgb.Dataset(X_imputed, label=y)\n",
    "    final_model = lgb.train(\n",
    "        params_with_seed, \n",
    "        full_train, \n",
    "        num_boost_round=avg_best_iter\n",
    "    )\n",
    "    \n",
    "    test_pred = final_model.predict(test_imputed)\n",
    "    ensemble_test_preds.append(test_pred)\n",
    "\n",
    "# Average ensemble predictions (robust to noise)\n",
    "test_pred_final = np.mean(ensemble_test_preds, axis=0)\n",
    "\n",
    "# Also calculate median for extra robustness (optional sanity check)\n",
    "test_pred_median = np.median(ensemble_test_preds, axis=0)\n",
    "\n",
    "# Use mean predictions (more stable for probability outputs)\n",
    "test_labels = np.argmax(test_pred_final, axis=1) + 1\n",
    "\n",
    "# Calculate prediction confidence and agreement\n",
    "prediction_confidence = np.max(test_pred_final, axis=1)\n",
    "ensemble_agreement = np.array([\n",
    "    np.mean([np.argmax(pred[i]) == np.argmax(test_pred_final[i]) \n",
    "             for pred in ensemble_test_preds])\n",
    "    for i in range(len(test_pred_final))\n",
    "])\n",
    "\n",
    "print(f\"\\nTest prediction confidence statistics:\")\n",
    "print(f\"  Mean: {prediction_confidence.mean():.4f}\")\n",
    "print(f\"  Median: {np.median(prediction_confidence):.4f}\")\n",
    "print(f\"  Min: {prediction_confidence.min():.4f}\")\n",
    "print(f\"  Max: {prediction_confidence.max():.4f}\")\n",
    "\n",
    "print(f\"\\nTest ensemble agreement statistics:\")\n",
    "print(f\"  Mean agreement: {ensemble_agreement.mean():.4f}\")\n",
    "print(f\"  High agreement (>0.8): {(ensemble_agreement > 0.8).sum()} samples\")\n",
    "print(f\"  Low agreement (<0.5): {(ensemble_agreement < 0.5).sum()} samples\")\n",
    "\n",
    "# Show class distribution in predictions\n",
    "print(\"\\nTest predicted class distribution:\")\n",
    "pred_counts = pd.Series(test_labels).value_counts().sort_index()\n",
    "for cls in pred_counts.index:\n",
    "    print(f\"  Class {int(cls)}: {pred_counts[cls]} samples ({100*pred_counts[cls]/len(test_labels):.2f}%)\")\n",
    "\n",
    "# Compare with training distribution\n",
    "print(\"\\nClass distribution comparison (Training → Test):\")\n",
    "for cls in sorted(class_counts.index):\n",
    "    train_pct = 100 * class_counts[cls] / len(y)\n",
    "    test_pct = 100 * pred_counts.get(cls, 0) / len(test_labels)\n",
    "    diff = test_pct - train_pct\n",
    "    print(f\"  Class {int(cls)}: {train_pct:.1f}% → {test_pct:.1f}% (Δ {diff:+.1f}%)\")\n",
    "\n",
    "# -----------------------------\n",
    "# 9. Save Test Results\n",
    "# -----------------------------\n",
    "output = np.column_stack([test_pred_final, test_labels])\n",
    "np.savetxt('testLabel_lightgbm.txt', output, \n",
    "           fmt='%.6f\\t%.6f\\t%.6f\\t%.6f\\t%d', \n",
    "           delimiter='\\t')\n",
    "\n",
    "# Also save ensemble agreement scores for analysis\n",
    "np.savetxt('testLabel_confidence.txt', \n",
    "           np.column_stack([test_labels, prediction_confidence, ensemble_agreement]),\n",
    "           fmt='%d\\t%.6f\\t%.6f',\n",
    "           header='predicted_label\\tconfidence\\tensemble_agreement',\n",
    "           comments='')\n",
    "\n",
    "print(f\"\\n✓ Test predictions saved to 'testLabel_lightgbm.txt'\")\n",
    "print(f\"✓ Test confidence metrics saved to 'testLabel_confidence.txt'\")\n",
    "print(f\"  - {len(test_labels)} predictions generated\")\n",
    "\n",
    "# -----------------------------\n",
    "# 10. Blind Data Prediction (if available)\n",
    "# -----------------------------\n",
    "print(\"\\n[9/9] Checking for blind data...\")\n",
    "\n",
    "try:\n",
    "    # Try to load blind data\n",
    "    blind_data = pd.read_csv('blindData.txt', header=None)\n",
    "    print(f\"✓ Blind data found: {blind_data.shape}\")\n",
    "    \n",
    "    # Preprocess blind data (same pipeline as test data)\n",
    "    print(\"\\nPreprocessing blind data...\")\n",
    "    blind_data = blind_data.replace('', np.nan).apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    # Verify feature count matches\n",
    "    if blind_data.shape[1] != X.shape[1]:\n",
    "        print(f\"⚠️  Warning: Blind data has {blind_data.shape[1]} features, expected {X.shape[1]}\")\n",
    "        print(\"   Attempting to proceed anyway...\")\n",
    "    \n",
    "    # Apply imputation\n",
    "    blind_imputed = imputer.transform(blind_data)\n",
    "    print(f\"✓ Blind data imputed: {blind_imputed.shape}\")\n",
    "    \n",
    "    # Generate ensemble predictions for blind data\n",
    "    print(\"\\nGenerating ensemble predictions for blind data...\")\n",
    "    ensemble_blind_preds = []\n",
    "    \n",
    "    for seed_idx, seed in enumerate(seeds):\n",
    "        print(f\"  Predicting with ensemble model {seed_idx + 1}/{len(seeds)} (seed={seed})...\")\n",
    "        \n",
    "        params_with_seed = best_params.copy()\n",
    "        params_with_seed['seed'] = seed\n",
    "        \n",
    "        # Use average best iteration from CV\n",
    "        avg_best_iter = int(np.mean([m.best_iteration for m in best_fold_models]))\n",
    "        \n",
    "        full_train = lgb.Dataset(X_imputed, label=y)\n",
    "        final_model = lgb.train(\n",
    "            params_with_seed, \n",
    "            full_train, \n",
    "            num_boost_round=avg_best_iter\n",
    "        )\n",
    "        \n",
    "        blind_pred = final_model.predict(blind_imputed)\n",
    "        ensemble_blind_preds.append(blind_pred)\n",
    "    \n",
    "    # Average ensemble predictions\n",
    "    blind_pred_final = np.mean(ensemble_blind_preds, axis=0)\n",
    "    blind_labels = np.argmax(blind_pred_final, axis=1) + 1\n",
    "    \n",
    "    # Calculate prediction confidence and agreement for blind data\n",
    "    blind_confidence = np.max(blind_pred_final, axis=1)\n",
    "    blind_agreement = np.array([\n",
    "        np.mean([np.argmax(pred[i]) == np.argmax(blind_pred_final[i]) \n",
    "                 for pred in ensemble_blind_preds])\n",
    "        for i in range(len(blind_pred_final))\n",
    "    ])\n",
    "    \n",
    "    print(f\"\\nBlind data prediction confidence statistics:\")\n",
    "    print(f\"  Mean: {blind_confidence.mean():.4f}\")\n",
    "    print(f\"  Median: {np.median(blind_confidence):.4f}\")\n",
    "    print(f\"  Min: {blind_confidence.min():.4f}\")\n",
    "    print(f\"  Max: {blind_confidence.max():.4f}\")\n",
    "    \n",
    "    print(f\"\\nBlind data ensemble agreement statistics:\")\n",
    "    print(f\"  Mean agreement: {blind_agreement.mean():.4f}\")\n",
    "    print(f\"  High agreement (>0.8): {(blind_agreement > 0.8).sum()} samples\")\n",
    "    print(f\"  Low agreement (<0.5): {(blind_agreement < 0.5).sum()} samples\")\n",
    "    \n",
    "    # Show predicted class distribution for blind data\n",
    "    print(\"\\nBlind data predicted class distribution:\")\n",
    "    blind_pred_counts = pd.Series(blind_labels).value_counts().sort_index()\n",
    "    for cls in blind_pred_counts.index:\n",
    "        print(f\"  Class {int(cls)}: {blind_pred_counts[cls]} samples ({100*blind_pred_counts[cls]/len(blind_labels):.2f}%)\")\n",
    "    \n",
    "    # Compare blind predictions with training and test distributions\n",
    "    print(\"\\nClass distribution comparison (Training → Test → Blind):\")\n",
    "    for cls in sorted(class_counts.index):\n",
    "        train_pct = 100 * class_counts[cls] / len(y)\n",
    "        test_pct = 100 * pred_counts.get(cls, 0) / len(test_labels)\n",
    "        blind_pct = 100 * blind_pred_counts.get(cls, 0) / len(blind_labels)\n",
    "        print(f\"  Class {int(cls)}: {train_pct:.1f}% → {test_pct:.1f}% → {blind_pct:.1f}%\")\n",
    "    \n",
    "    # Save blind data predictions\n",
    "    blind_output = np.column_stack([blind_pred_final, blind_labels])\n",
    "    np.savetxt('blindLabel_lightgbm.txt', blind_output, \n",
    "               fmt='%.6f\\t%.6f\\t%.6f\\t%.6f\\t%d', \n",
    "               delimiter='\\t')\n",
    "    \n",
    "    # Save blind data confidence metrics\n",
    "    np.savetxt('blindLabel_confidence.txt', \n",
    "               np.column_stack([blind_labels, blind_confidence, blind_agreement]),\n",
    "               fmt='%d\\t%.6f\\t%.6f',\n",
    "               header='predicted_label\\tconfidence\\tensemble_agreement',\n",
    "               comments='')\n",
    "    \n",
    "    print(f\"\\n✓ Blind predictions saved to 'blindLabel_lightgbm.txt'\")\n",
    "    print(f\"✓ Blind confidence metrics saved to 'blindLabel_confidence.txt'\")\n",
    "    print(f\"  - {len(blind_labels)} predictions generated\")\n",
    "    \n",
    "    # Store for final summary\n",
    "    blind_data_processed = True\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"ℹ️  No blind data file found (blindData.txt)\")\n",
    "    print(\"   Skipping blind data prediction...\")\n",
    "    blind_data_processed = False\n",
    "except Exception as e:\n",
    "    print(f\"⚠️  Error processing blind data: {str(e)}\")\n",
    "    print(\"   Skipping blind data prediction...\")\n",
    "    blind_data_processed = False\n",
    "\n",
    "# -----------------------------\n",
    "# Final Summary\n",
    "# -----------------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✓ COMPLETED SUCCESSFULLY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nSummary of outputs:\")\n",
    "print(f\"  1. Test predictions: testLabel_lightgbm.txt ({len(test_labels)} samples)\")\n",
    "print(f\"  2. Test confidence: testLabel_confidence.txt\")\n",
    "if blind_data_processed:\n",
    "    print(f\"  3. Blind predictions: blindLabel_lightgbm.txt ({len(blind_labels)} samples)\")\n",
    "    print(f\"  4. Blind confidence: blindLabel_confidence.txt\")\n",
    "print(f\"\\nModel Performance:\")\n",
    "print(f\"  - Cross-validation accuracy: {best_score:.4f} ± {best_std:.4f}\")\n",
    "print(f\"  - Macro-average AUC: {macro_auc:.4f}\")\n",
    "print(f\"  - Ensemble size: {len(seeds)} models\")\n",
    "print(f\"  - Best configuration: Config {best_config_idx + 1}\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ea9658-af73-4673-bce7-de1285ccfdef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c493440-b655-49e2-b81f-5d954b749e5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (py39)",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
