{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a192752a-d480-4a5c-a9c0-8fee2fd75da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from lightgbm.callback import early_stopping, log_evaluation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report\n",
    "from sklearn.preprocessing import RobustScaler, QuantileTransformer, StandardScaler\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import stats\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"NEURAL NETWORK META-LEARNER + LIGHTGBM STACKING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load data\n",
    "# -----------------------------\n",
    "print(\"\\n[1/11] Loading data...\")\n",
    "X = pd.read_csv('trainingData.txt', header=None)\n",
    "y = pd.read_csv('trainingTruth.txt', header=None, names=['label']).squeeze()\n",
    "test_data = pd.read_csv('testData.txt', header=None)\n",
    "\n",
    "print(f\"Training data shape: {X.shape}\")\n",
    "print(f\"Test data shape: {test_data.shape}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Data Preprocessing\n",
    "# -----------------------------\n",
    "print(\"\\n[2/11] Preprocessing...\")\n",
    "\n",
    "X = X.replace('', np.nan).apply(pd.to_numeric, errors='coerce')\n",
    "test_data = test_data.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "valid_mask = ~y.isna()\n",
    "X = X[valid_mask].reset_index(drop=True)\n",
    "y = y[valid_mask].reset_index(drop=True)\n",
    "\n",
    "print(f\"After cleaning: {X.shape[0]} samples, {X.shape[1]} features\")\n",
    "\n",
    "class_counts = y.value_counts().sort_index()\n",
    "print(\"\\nClass distribution:\")\n",
    "for cls in class_counts.index:\n",
    "    print(f\"  Class {int(cls)}: {class_counts[cls]} ({100*class_counts[cls]/len(y):.2f}%)\")\n",
    "\n",
    "is_imbalanced = (class_counts.max() / class_counts.min()) > 1.5\n",
    "y = y - 1  # Zero-based\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Feature Engineering\n",
    "# -----------------------------\n",
    "print(\"\\n[3/11] Feature engineering...\")\n",
    "\n",
    "missing_pct = X.isna().sum() / len(X) * 100\n",
    "\n",
    "# Imputation strategies\n",
    "imputer_median = SimpleImputer(strategy='median')\n",
    "X_imputed = imputer_median.fit_transform(X)\n",
    "test_imputed = imputer_median.transform(test_data)\n",
    "\n",
    "# Missing indicators\n",
    "important_missing_cols = (missing_pct > 5).values\n",
    "missing_indicators = X.isna().astype(int).values[:, important_missing_cols]\n",
    "test_missing_indicators = test_data.isna().astype(int).values[:, important_missing_cols]\n",
    "\n",
    "# Statistical features\n",
    "def create_statistical_features(data):\n",
    "    features = []\n",
    "    features.append(np.mean(data, axis=1).reshape(-1, 1))\n",
    "    features.append(np.std(data, axis=1).reshape(-1, 1))\n",
    "    features.append(np.median(data, axis=1).reshape(-1, 1))\n",
    "    features.append(np.min(data, axis=1).reshape(-1, 1))\n",
    "    features.append(np.max(data, axis=1).reshape(-1, 1))\n",
    "    features.append((np.max(data, axis=1) - np.min(data, axis=1)).reshape(-1, 1))\n",
    "    features.append(stats.skew(data, axis=1).reshape(-1, 1))\n",
    "    features.append(stats.kurtosis(data, axis=1).reshape(-1, 1))\n",
    "    features.append(np.percentile(data, 25, axis=1).reshape(-1, 1))\n",
    "    features.append(np.percentile(data, 75, axis=1).reshape(-1, 1))\n",
    "    return np.hstack(features)\n",
    "\n",
    "row_features = create_statistical_features(X_imputed)\n",
    "test_row_features = create_statistical_features(test_imputed)\n",
    "\n",
    "print(f\"Created {row_features.shape[1]} statistical features\")\n",
    "print(f\"Created {missing_indicators.shape[1]} missingness indicators\")\n",
    "\n",
    "# Feature selection\n",
    "mi_scores = mutual_info_classif(X_imputed, y, random_state=42, n_neighbors=5)\n",
    "mi_threshold = np.percentile(mi_scores, 20)  # Keep top 80%\n",
    "selected_features = mi_scores > mi_threshold\n",
    "\n",
    "X_selected = X_imputed[:, selected_features]\n",
    "test_selected = test_imputed[:, selected_features]\n",
    "\n",
    "print(f\"Selected {selected_features.sum()} features via mutual information\")\n",
    "\n",
    "# Quantile transformation\n",
    "quantile_transformer = QuantileTransformer(output_distribution='normal', random_state=42)\n",
    "X_quantile = quantile_transformer.fit_transform(X_selected)\n",
    "test_quantile = quantile_transformer.transform(test_selected)\n",
    "\n",
    "# PCA features\n",
    "pca = PCA(n_components=50, random_state=42)\n",
    "X_pca = pca.fit_transform(X_quantile)\n",
    "test_pca = pca.transform(test_quantile)\n",
    "\n",
    "# Combine features\n",
    "X_final = np.hstack([X_selected, X_quantile, X_pca, row_features, missing_indicators])\n",
    "test_final = np.hstack([test_selected, test_quantile, test_pca, test_row_features, test_missing_indicators])\n",
    "\n",
    "print(f\"Final feature count: {X_final.shape[1]}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Base Model Configurations\n",
    "# -----------------------------\n",
    "print(\"\\n[4/11] Configuring diverse base models...\")\n",
    "\n",
    "base_model_configs = [\n",
    "    {\n",
    "        'objective': 'multiclass', 'num_class': 4, 'metric': 'multi_logloss',\n",
    "        'boosting_type': 'gbdt', 'learning_rate': 0.01, 'num_leaves': 127,\n",
    "        'max_depth': 10, 'min_data_in_leaf': 15, 'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.5,\n",
    "        'lambda_l2': 0.5, 'verbose': -1, 'is_unbalance': is_imbalanced, 'seed': 42\n",
    "    },\n",
    "    {\n",
    "        'objective': 'multiclass', 'num_class': 4, 'metric': 'multi_logloss',\n",
    "        'boosting_type': 'gbdt', 'learning_rate': 0.008, 'num_leaves': 95,\n",
    "        'max_depth': 12, 'min_data_in_leaf': 12, 'feature_fraction': 0.75,\n",
    "        'bagging_fraction': 0.75, 'bagging_freq': 4, 'lambda_l1': 0.3,\n",
    "        'lambda_l2': 0.7, 'verbose': -1, 'is_unbalance': is_imbalanced, 'seed': 123\n",
    "    },\n",
    "    {\n",
    "        'objective': 'multiclass', 'num_class': 4, 'metric': 'multi_logloss',\n",
    "        'boosting_type': 'dart', 'learning_rate': 0.015, 'num_leaves': 80,\n",
    "        'max_depth': 9, 'min_data_in_leaf': 18, 'feature_fraction': 0.85,\n",
    "        'bagging_fraction': 0.85, 'drop_rate': 0.1, 'skip_drop': 0.5,\n",
    "        'verbose': -1, 'is_unbalance': is_imbalanced, 'seed': 456\n",
    "    },\n",
    "    {\n",
    "        'objective': 'multiclass', 'num_class': 4, 'metric': 'multi_logloss',\n",
    "        'boosting_type': 'gbdt', 'learning_rate': 0.012, 'num_leaves': 110,\n",
    "        'max_depth': 11, 'min_data_in_leaf': 10, 'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.9, 'bagging_freq': 2, 'lambda_l1': 0.1,\n",
    "        'lambda_l2': 0.3, 'verbose': -1, 'is_unbalance': is_imbalanced, 'seed': 789\n",
    "    },\n",
    "    {\n",
    "        'objective': 'multiclass', 'num_class': 4, 'metric': 'multi_logloss',\n",
    "        'boosting_type': 'gbdt', 'learning_rate': 0.02, 'num_leaves': 63,\n",
    "        'max_depth': 8, 'min_data_in_leaf': 20, 'feature_fraction': 0.7,\n",
    "        'bagging_fraction': 0.7, 'bagging_freq': 6, 'lambda_l1': 0.8,\n",
    "        'lambda_l2': 1.0, 'verbose': -1, 'is_unbalance': is_imbalanced, 'seed': 2024\n",
    "    }\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Generate Base Model Predictions (Stacking)\n",
    "# -----------------------------\n",
    "print(\"\\n[5/11] Training base models and generating meta-features...\")\n",
    "\n",
    "n_folds = 10\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Store out-of-fold predictions for meta-learner training\n",
    "oof_predictions = np.zeros((len(X_final), len(base_model_configs), 4))\n",
    "test_predictions = np.zeros((len(test_final), len(base_model_configs), 4))\n",
    "\n",
    "for model_idx, params in enumerate(base_model_configs):\n",
    "    print(f\"\\n--- Base Model {model_idx + 1}/{len(base_model_configs)} ---\")\n",
    "    \n",
    "    fold_test_preds = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X_final, y)):\n",
    "        X_train, X_val = X_final[train_idx], X_final[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        train_dataset = lgb.Dataset(X_train, label=y_train)\n",
    "        valid_dataset = lgb.Dataset(X_val, label=y_val, reference=train_dataset)\n",
    "        \n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_dataset,\n",
    "            num_boost_round=3000,\n",
    "            valid_sets=[valid_dataset],\n",
    "            callbacks=[early_stopping(stopping_rounds=150), log_evaluation(period=0)]\n",
    "        )\n",
    "        \n",
    "        # Out-of-fold predictions for meta-learner\n",
    "        oof_predictions[val_idx, model_idx, :] = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "        \n",
    "        # Test predictions\n",
    "        fold_test_preds.append(model.predict(test_final, num_iteration=model.best_iteration))\n",
    "    \n",
    "    # Average test predictions across folds\n",
    "    test_predictions[:, model_idx, :] = np.mean(fold_test_preds, axis=0)\n",
    "    \n",
    "    # Evaluate base model\n",
    "    base_pred_labels = np.argmax(oof_predictions[:, model_idx, :], axis=1)\n",
    "    base_accuracy = accuracy_score(y, base_pred_labels)\n",
    "    print(f\"  Base Model {model_idx + 1} OOF Accuracy: {base_accuracy:.4f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Neural Network Meta-Learner Architecture\n",
    "# -----------------------------\n",
    "print(\"\\n[6/11] Defining neural network meta-learner...\")\n",
    "\n",
    "class MetaLearner(nn.Module):\n",
    "    def __init__(self, n_base_models, n_classes, dropout_rate=0.3):\n",
    "        super(MetaLearner, self).__init__()\n",
    "        \n",
    "        input_size = n_base_models * n_classes  # Flattened predictions from all base models\n",
    "        \n",
    "        # Deep architecture with residual connections\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.dropout3 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.fc4 = nn.Linear(64, 32)\n",
    "        self.bn4 = nn.BatchNorm1d(32)\n",
    "        self.dropout4 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.fc_out = nn.Linear(32, n_classes)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Input: [batch_size, n_base_models, n_classes]\n",
    "        x = x.view(x.size(0), -1)  # Flatten to [batch_size, n_base_models * n_classes]\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout3(x)\n",
    "        \n",
    "        x = self.fc4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout4(x)\n",
    "        \n",
    "        x = self.fc_out(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# -----------------------------\n",
    "# 7. Train Meta-Learner\n",
    "# -----------------------------\n",
    "print(\"\\n[7/11] Training neural network meta-learner...\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Prepare meta-features (OOF predictions from base models)\n",
    "X_meta = oof_predictions.reshape(len(X_final), -1)\n",
    "y_meta = y.values\n",
    "\n",
    "# Split for meta-learner validation\n",
    "meta_skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "meta_models = []\n",
    "meta_val_scores = []\n",
    "\n",
    "for meta_fold, (meta_train_idx, meta_val_idx) in enumerate(meta_skf.split(X_meta, y_meta)):\n",
    "    print(f\"\\n  Meta-fold {meta_fold + 1}/5\")\n",
    "    \n",
    "    X_meta_train, X_meta_val = X_meta[meta_train_idx], X_meta[meta_val_idx]\n",
    "    y_meta_train, y_meta_val = y_meta[meta_train_idx], y_meta[meta_val_idx]\n",
    "    \n",
    "    # Convert to PyTorch tensors\n",
    "    X_train_tensor = torch.FloatTensor(X_meta_train)\n",
    "    y_train_tensor = torch.LongTensor(y_meta_train)\n",
    "    X_val_tensor = torch.FloatTensor(X_meta_val)\n",
    "    y_val_tensor = torch.LongTensor(y_meta_val)\n",
    "    \n",
    "    # Create DataLoader\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    \n",
    "    # Initialize model\n",
    "    meta_model = MetaLearner(n_base_models=len(base_model_configs), n_classes=4, dropout_rate=0.3)\n",
    "    meta_model = meta_model.to(device)\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(meta_model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=10, verbose=False)\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_acc = 0\n",
    "    patience_counter = 0\n",
    "    max_patience = 30\n",
    "    \n",
    "    for epoch in range(200):\n",
    "        meta_model.train()\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            batch_X = batch_X.view(batch_X.size(0), len(base_model_configs), 4)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = meta_model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Validation\n",
    "        meta_model.eval()\n",
    "        with torch.no_grad():\n",
    "            X_val_device = X_val_tensor.to(device).view(-1, len(base_model_configs), 4)\n",
    "            val_outputs = meta_model(X_val_device)\n",
    "            val_preds = torch.argmax(val_outputs, dim=1).cpu().numpy()\n",
    "            val_acc = accuracy_score(y_meta_val, val_preds)\n",
    "        \n",
    "        scheduler.step(val_acc)\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            best_model_state = meta_model.state_dict().copy()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if patience_counter >= max_patience:\n",
    "            break\n",
    "    \n",
    "    # Load best model\n",
    "    meta_model.load_state_dict(best_model_state)\n",
    "    meta_models.append(meta_model)\n",
    "    meta_val_scores.append(best_val_acc)\n",
    "    \n",
    "    print(f\"    Best validation accuracy: {best_val_acc:.4f}\")\n",
    "\n",
    "avg_meta_score = np.mean(meta_val_scores)\n",
    "print(f\"\\n  Average meta-learner CV accuracy: {avg_meta_score:.4f} ± {np.std(meta_val_scores):.4f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 8. Evaluate Meta-Learner on Full OOF\n",
    "# -----------------------------\n",
    "print(\"\\n[8/11] Evaluating meta-learner on full out-of-fold predictions...\")\n",
    "\n",
    "meta_model_ensemble = meta_models[0]\n",
    "meta_model_ensemble.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    X_meta_tensor = torch.FloatTensor(X_meta).to(device).view(-1, len(base_model_configs), 4)\n",
    "    oof_meta_outputs = meta_model_ensemble(X_meta_tensor)\n",
    "    oof_meta_preds = torch.argmax(oof_meta_outputs, dim=1).cpu().numpy()\n",
    "\n",
    "meta_accuracy = accuracy_score(y, oof_meta_preds)\n",
    "print(f\"Meta-learner OOF Accuracy: {meta_accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nMeta-learner Classification Report:\")\n",
    "print(classification_report(y, oof_meta_preds, \n",
    "                          target_names=[f'Class {i+1}' for i in range(4)],\n",
    "                          digits=4))\n",
    "\n",
    "# Compare with simple averaging\n",
    "avg_oof_preds = np.mean(oof_predictions, axis=1)\n",
    "avg_pred_labels = np.argmax(avg_oof_preds, axis=1)\n",
    "avg_accuracy = accuracy_score(y, avg_pred_labels)\n",
    "print(f\"\\nSimple averaging baseline: {avg_accuracy:.4f}\")\n",
    "print(f\"Meta-learner improvement: {meta_accuracy - avg_accuracy:+.4f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 9. Meta-Learner Predictions on Test Set\n",
    "# -----------------------------\n",
    "print(\"\\n[9/11] Generating meta-learner predictions on test set...\")\n",
    "\n",
    "# Prepare test meta-features\n",
    "X_test_meta = test_predictions.reshape(len(test_final), -1)\n",
    "\n",
    "# Ensemble all meta-models\n",
    "test_meta_probs = []\n",
    "\n",
    "for meta_model in meta_models:\n",
    "    meta_model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_test_tensor = torch.FloatTensor(X_test_meta).to(device).view(-1, len(base_model_configs), 4)\n",
    "        test_outputs = meta_model(X_test_tensor)\n",
    "        test_probs = torch.softmax(test_outputs, dim=1).cpu().numpy()\n",
    "        test_meta_probs.append(test_probs)\n",
    "\n",
    "# Average predictions from all meta-models\n",
    "final_test_probs = np.mean(test_meta_probs, axis=0)\n",
    "final_test_labels = np.argmax(final_test_probs, axis=1) + 1\n",
    "\n",
    "# -----------------------------\n",
    "# 10. Analysis and Diagnostics\n",
    "# -----------------------------\n",
    "print(\"\\n[10/11] Prediction analysis...\")\n",
    "\n",
    "prediction_confidence = np.max(final_test_probs, axis=1)\n",
    "print(f\"\\nPrediction confidence: {prediction_confidence.mean():.4f} ± {prediction_confidence.std():.4f}\")\n",
    "print(f\"High confidence (>0.9): {(prediction_confidence > 0.9).sum()} samples\")\n",
    "print(f\"Low confidence (<0.6): {(prediction_confidence < 0.6).sum()} samples\")\n",
    "\n",
    "print(\"\\nPredicted class distribution:\")\n",
    "pred_counts = pd.Series(final_test_labels).value_counts().sort_index()\n",
    "for cls in pred_counts.index:\n",
    "    print(f\"  Class {int(cls)}: {pred_counts[cls]} ({100*pred_counts[cls]/len(final_test_labels):.2f}%)\")\n",
    "\n",
    "# -----------------------------\n",
    "# 11. Save Results\n",
    "# -----------------------------\n",
    "print(\"\\n[11/11] Saving results...\")\n",
    "\n",
    "output = np.column_stack([final_test_probs, final_test_labels])\n",
    "np.savetxt('testLabel_metalearner.txt', output, \n",
    "           fmt='%.6f\\t%.6f\\t%.6f\\t%.6f\\t%d', \n",
    "           delimiter='\\t')\n",
    "\n",
    "# Save detailed diagnostics\n",
    "np.savetxt('testLabel_diagnostics.txt',\n",
    "           np.column_stack([final_test_labels, prediction_confidence]),\n",
    "           fmt='%d\\t%.6f',\n",
    "           header='predicted_label\\tconfidence',\n",
    "           comments='')\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✓ COMPLETED\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nResults saved to 'testLabel_metalearner.txt'\")\n",
    "print(f\"Expected accuracy: {meta_accuracy:.4f}\")\n",
    "print(f\"Improvement over simple averaging: {meta_accuracy - avg_accuracy:+.4f}\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (py39)",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
